{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INdFcdQdx_6L",
        "outputId": "287f9277-9e7f-4a2c-d0a7-8f52a202363d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Searching for: Startup India\n",
            "üìù Searching: Startup India official website\n",
            "üìù Searching: Startup India government scheme\n",
            "üìù Searching: Startup India 2024\n",
            "üìù Searching: Startup India startupindia.gov.in\n",
            "\n",
            "Found 0 unique results:\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "\n",
        "def working_gov_search(topic):\n",
        "    print(f\" Searching for: {topic}\")\n",
        "\n",
        "    def search_google(query, num_results=10):\n",
        "        \"\"\"Search Google using custom requests\"\"\"\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "\n",
        "        urls = []\n",
        "        try:\n",
        "            search_url = f\"https://www.google.com/search?q={query.replace(' ', '+')}&num={num_results}\"\n",
        "\n",
        "            response = requests.get(search_url, headers=headers)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            for link in soup.find_all('a', href=True):\n",
        "                href = link['href']\n",
        "                if href.startswith('/url?q='):\n",
        "                    url = href.split('/url?q=')[1].split('&')[0]\n",
        "                    if url.startswith('http') and 'google.com' not in url:\n",
        "                        urls.append(url)\n",
        "\n",
        "            return urls[:num_results]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Search error: {e}\")\n",
        "            return []\n",
        "\n",
        "    queries = [\n",
        "        f\"{topic} official website\",\n",
        "        f\"{topic} government scheme\",\n",
        "        f\"{topic} 2024\",\n",
        "        f\"{topic} startupindia.gov.in\"\n",
        "    ]\n",
        "\n",
        "    all_urls = []\n",
        "    for query in queries:\n",
        "        print(f\"üìù Searching: {query}\")\n",
        "        urls = search_google(query, 5)\n",
        "        all_urls.extend(urls)\n",
        "        time.sleep(2)\n",
        "\n",
        "    unique_urls = []\n",
        "    for url in all_urls:\n",
        "        if url not in unique_urls:\n",
        "            unique_urls.append(url)\n",
        "\n",
        "    print(f\"\\nFound {len(unique_urls)} unique results:\")\n",
        "    for i, url in enumerate(unique_urls, 1):\n",
        "        print(f\"   {i}. {url}\")\n",
        "\n",
        "    return unique_urls\n",
        "\n",
        "topic = \"Startup India\"\n",
        "results = working_gov_search(topic)"
      ]
    }
  ]
}